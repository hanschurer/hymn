---
title: An Open Problem in AI
date: '2021-05-14'
tags: ['game-development']
draft: false
summary: 'An open problem in AI and how it related to game AI'
---
# An open problem in AI
A large part of human success stems from our ability to collaborate. Artificial intelligence-
powered machines are playing an increasing role in our lives, it will be crucial to enhancing
their ability to cooperate and facilitate collaboration to have better efficiency .
In the field of AI , recent advances have been limited to individual agents operating in
constrained environments. The ability to stimulate competition and collaboration among AI
agents will be critical to enabling collective knowledge and building dynamics for the
development of AI. (KDnuggets, 2019)

This field of open problem is called cooperative AI. Their main object of research is the
creation of cooperative agents and the build tools to facilitate collaboration between a group
of agents and there are still many open problems in the area of cooperation for AI, such as
how to reconcile the degree of common versus conflicting interests among agents and most
important: how to cooperate among kinds of agents, such as machines, humans, or
organizations? (Dafoe et al, 2020)

# How it relates to Game AI.
A multi-agent system (MAS) is a computer system composed of multiple interacting
intelligent agents (J. Hu et al., 2020). All the agents in it have the same goal. The main
difficulty in such systems is how to solve the coordination problem: how to ensure that each
agent's decisions are beneficial to the team and that they work together to produce the optimal
solution?

Multi-agent cooperation has made some progress in the field of games. Jaderberg et al (2019)
designs a computer program to playing the capture-the-flag mode in the video game Quake III
Arena, in which two multiplayer teams compete to capture the other team's flag. Through
thousands of hours of training, these agents have gradually learned the same successful
strategies used by human players.

Zemzem & Tagina (2018) proposed and evaluated TM_Qlearning which a multi-subject
reinforcement learning algorithm combining traditional Q-learning. This approach is
particularly effective in games, especially in unknown and ad hoc settings, because it
improves thematic coordination and accelerates learning by proposing several new
cooperative selection strategies.

OpenAI (2019) uses a multi-agent system to produce hide-and-seek games, where up to six
different strategies emerge as agents confront each other in hide-and-seek. Each new strategy
puts a previously non-existent pressure on the agent to move to the next stage. The results
showed that agents emerged with surprising behaviors such as Box surfing, Endless running,
and Ramp exploitation (hiders and seekers). These acts go beyond even the imagination of the
players.

This is particularly important for in-game AI, where multiple agents can cooperate with each
other through reinforcement learning to choose the optimal strategy for cooperation or against
players in unpredictable environments. By combining the effectiveness of TM_Qlearning,
(Zemzem & Tagina, 2018) confirmed that this algorithm achieved good effectiveness in a
hunting game demonstration.

Similarly, in game-based reinforcement domain learning, great progress has been made in the
past years on two-player zero-sum games, such as chess and Go (Silver et al., 2018), Starcraft
II (Vinyals et al., 2019), (two-player) poker (Noam Brown and Anton Bakhtin, 2020) and
Two-player tournaments. (Dafoe et al., 2020)

These studies confirm that in the field of AI collaboration, reinforcement learning will be the
future trend to solve this open problem: how to cooperate among kinds of agents, such as
machines, humans, or organizations?
